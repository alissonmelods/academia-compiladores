{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise léxica\n",
    "\n",
    "A função do analisador léxico, também chamado _scanner_, é **fazer a leitura do programa fonte, caractere a caractere, e traduzi-lo para uma sequência de símbolos léxicos, também chamados _tokens_**.\n",
    "\n",
    "Uma linguagem é um conjunto de palavras formadas por símbolos de um determinado alfabeto. Tokens de uma LP constituem uma _linguagem regular_. \n",
    "\n",
    "## De linguagens formais\n",
    "\n",
    "Uma gramática $G$ é um mecanismo para regar sentenças (palavras) de uma linguagem e é definida por: $(N, T, P, S)$, onde:\n",
    "* $N$ é um conjunto de símbolos não terminais\n",
    "* $T$ é um conjunto de símbolos terminais\n",
    "* $P$ é um conjunto de regras de produção\n",
    "* $S$ é o símbolo inicial da gramática\n",
    "\n",
    "A _linguagem gerada_ por $G$, denotada por $L(G)$ é o conjunto formado por todas as sentenças de símbolos terminais deriváveis a partir do símbolo inicial $S$, ou seja:\n",
    "\n",
    "\\begin{align*}\n",
    "L(G) = \\{ s | s \\in T^* \\wedge S \\Rightarrow s \\}\n",
    "\\end{align*}\n",
    "\n",
    "### Expressões regulares\n",
    "\n",
    "Uma expresão regular $r$ sobre um conjunto de símbolos $T$ representa uma linguagem $L(r)$.\n",
    "\n",
    "## Tokens\n",
    "\n",
    "Os tokens são as unidades básicas do texto do programa. Cada token é representado por três informações:\n",
    "* **classe** (ex.: identificadores, constantes numéricas, cadeias de caracteres, palavras reservadas, operadores, separadores)\n",
    "* **valor do token** (ex.: o número representado por uma constante numérica)\n",
    "* **posição do token** (local do texto, linha e coluna, onde ocorreu o token)\n",
    "\n",
    "## Especificação\n",
    "\n",
    "A especificação de um analisador léxico descreve o conjunto de tokens que formam a linguagem, incluindo também a indicação de quais caracteres podem ser ignorados (ex.: espaços em branco entre tokens e comentários).\n",
    "\n",
    "As palavras-reservadas da linguagem (_keywords_) são armazenadas em uma tabela, que é examinada cada vez quem um identificador é reconhecido. Se o token ocorre na tabela, então trata-se de uma _keyword_, senão, é um identificador. \n",
    "\n",
    "**Exemplo**: Considere uma linguagem de programação cujos tokens são os seguintes:\n",
    "* identificadores formados por uma letra (L) seguida, opcionalmente, por uma ou mais letras e dígitos (D)\n",
    "* números inteiros formados por um ou mais dígitos (D)\n",
    "* espaços em branco (B) são ignorados\n",
    "\n",
    "Geralmente, um _autômato finito_ é utilizado para representar o analisador léxico, mas a implementação pode ocorrer de diversas formas, como lendo o programa fonte a cada caractere e avaliando condicionais ou utilizando-se de expressões regulares.\n",
    "\n",
    "## Tabela de símbolos\n",
    "\n",
    "A tabela de símbolos associa atributos (como tipo, escopo, limites no caso de vetores) ao snomes definidos pelo programador. Ela começa a ser construída durante a análise léxica, no reconhecimento dos identificadores. Uma estratégia de implementação é utilizar uma _tabela hash_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
